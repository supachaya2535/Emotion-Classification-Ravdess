{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/supachaya2535/Emotion-Classification-Ravdess/blob/master/CNN_NEWS_NER.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_-lgnM8wwqC5",
        "outputId": "e05d1cda-222b-456c-f6b2-252bf50793e8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m225.4/225.4 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m794.4/794.4 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m29.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.9/75.9 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m44.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m192.4/192.4 kB\u001b[0m \u001b[31m17.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.7/46.7 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.9/76.9 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "tensorflow-probability 0.22.0 requires typing-extensions<4.6.0, but you have typing-extensions 4.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install openai langchain tiktoken -q"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.llms import OpenAI\n",
        "from langchain.chains import LLMChain\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "import openai\n",
        "import os\n"
      ],
      "metadata": {
        "id": "hVg5qaENwr12"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MODEL"
      ],
      "metadata": {
        "id": "FJn_4nxrzLl7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"OPENAI_API_KEY\"] = \"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\"\n",
        "openai.api_key = \"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\""
      ],
      "metadata": {
        "id": "jcyn1AP9xgMK"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = ChatOpenAI(temperature=0,model_name = \"gpt-3.5-turbo-1106\")"
      ],
      "metadata": {
        "id": "MRRwgYZKw2zr"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnn_news = {\"head\" : \"Jeff Bezos’ Blue Origin launches rocket after failed 2022 flight attempt\",\n",
        "         \"body\" : \"\"\"\n",
        "Blue Origin’s tourism rocket — designed to vault paying customers on brief trips to the edge of space — successfully launched Tuesday morning on an uncrewed science mission.\n",
        "The New Shepard rocket lifted off at 11:43 a.m. ET from Blue Origin’s facilities on a private ranch in West Texas. The 33 science experiments on board experienced a few minutes of microgravity before safely returning to Earth.\n",
        "The rocket booster touched down about seven minutes after launch, followed by a safe landing of the capsule about 10 minutes after launch.\n",
        "  The first launch attempt was scrubbed Monday due to teams working a ground system issue. But mission control didn’t appear to encounter any issues during Tuesday’s launch, and the test flight quickly worked its way through the team’s list of objectives.\n",
        "Though no one was on board the flight, the success could tee up Blue Origin to restart its trips to space for thrill seekers.\n",
        "“We look forward to flying our next crewed flight soon,” said Erika Wagner, senior director of emerging market development for Blue Origin, on the live launch broadcast at the conclusion of the flight.\n",
        "The anticipated return to flight occurred after the Jeff Bezos-founded company spent more than a year recuperating from a failed uncrewed test flight.\n",
        "A New Shepard rocket and spacecraft was set to launch a batch of science instruments on September 12, 2022. But one minute into flight, the rocket endured Max Q — an aerospace term that refers to a moment of maximum stress on a vehicle at a relatively low altitude where the atmosphere is still fairly thick, and the rocket is moving at nearly the speed of sound.\n",
        "Around that time, the rocket appeared to emit a massive burst of flames. The New Shepard capsule, which rides atop the rocket, then initiated its launch abort system — firing up a small engine to blast itself safely away from the malfunctioning rocket. That system worked as intended, parachuting the capsule to a safe landing.\n",
        "Blue Origin later revealed that the cause of the failure was a problem with the engine nozzle, a large cone that directs the flaming exhaust at the rocket’s bottom. Onboard computers accurately detected the failure and shut the engine down, according to the company.\n",
        "Before the September 2022 failure, New Shepard rockets had flown 22 consecutive successful missions — including six with passengers on board. Bezos flew aboard the rocket in 2021.\n",
        "\"\"\",\n",
        "         }"
      ],
      "metadata": {
        "id": "VL4jqsHdzJho"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# NO POS"
      ],
      "metadata": {
        "id": "nxT349rBPl_1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = f\"\"\"Hello! I need your help with a task related to understanding and extracting important information from text. Specifically, I'm interested in identifying and classifying named entities (people's names, place names, product names, countries, important words, and specific/scientific words) in a given text.\n",
        "\n",
        "Task:\n",
        "\n",
        "Please use ChatGPT to perform a Named Entity Recognition (NER) task on the provided text. Extract and categorize the named entities, and provide information on their types in JSON format. For example, if the text mentions a person's name, place name, product name, country, important word, or specific/scientific word, please identify and label them accordingly in the JSON output. Additionally, include any relevant details about the named entities you find.\n",
        "\n",
        "Instructions:\n",
        "\n",
        "1.Begin by introducing yourself and acknowledging the task.\n",
        "2.Analyze the given text for named entities.\n",
        "3.Provide the output in JSON format, with each named entity as a key-value pair, where the key is the type of the entity (e.g., People Name, Place Name, Product Name, Country, Importance Word, Specific/Scientific Word) and the value is the actual entity or additional details.\n",
        "4.Ensure that the JSON output is well-structured and easy to understand.\n",
        "\n",
        "Sample Text for NER:\n",
        "\n",
        "The famous scientist Marie Curie was born on November 7, 1867, in Warsaw, Poland. She made groundbreaking contributions to the field of physics and chemistry. Curie was the first woman to win a Nobel Prize and remains an inspiration for scientists worldwide.\n",
        "\n",
        "Expected Output (JSON):\n",
        "\n",
        "  People Name:  [Marie Curie],\n",
        "  Importance Word: [groundbreaking],\n",
        "  Specific/Scientific Word: [physics, chemistry],\n",
        "  Place Name: [\n",
        "    City: Warsaw,\n",
        "    Country: Poland\n",
        "  ],\n",
        "  Country: [Poland],\n",
        "  Product Name: [Nobel Prize]\n",
        "\n",
        "Text input\n",
        "{cnn_news['body']}\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "vb_3uDh80Dwz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "answer = llm.predict(prompt)\n",
        "print(answer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DRyHW_MN2tK1",
        "outputId": "75fd987f-e36a-4fe1-ac1b-1a4fe25234af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"Product Name\": [\"New Shepard rocket\"],\n",
            "  \"Place Name\": [\n",
            "    {\n",
            "      \"Facility\": \"Blue Origin’s facilities\",\n",
            "      \"City\": \"West Texas\"\n",
            "    }\n",
            "  ],\n",
            "  \"People Name\": [\"Erika Wagner\", \"Jeff Bezos\"],\n",
            "  \"Specific/Scientific Word\": [\"microgravity\", \"Max Q\", \"aerospace\", \"engine nozzle\"],\n",
            "  \"Importance Word\": [\"uncrewed\", \"successful\", \"failed\"],\n",
            "  \"Country\": [\"United States\"]\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cgiX5JazPekY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# POS\n"
      ],
      "metadata": {
        "id": "cEedv5XvPtC4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = f\"\"\"Hello! I need your help with a task related to understanding and extracting important information from text. Specifically, I'm interested in identifying and classifying named entities (people's names, place names, product names, countries, important words, and specific/scientific words) in a given text. Additionally, I'd like to know the part-of-speech for each word.\n",
        "\n",
        "Task:\n",
        "\n",
        "Please use ChatGPT to perform a Named Entity Recognition (NER) task on the provided text. Extract and categorize the named entities, provide information on their types, and include the part-of-speech for each word in JSON format. For example, if the text mentions a person's name, place name, product name, country, important word, or specific/scientific word, please identify and label them accordingly in the JSON output. Additionally, include the part-of-speech for each word.\n",
        "\n",
        "Instructions:\n",
        "\n",
        "1.Begin by introducing yourself and acknowledging the task.\n",
        "2.Analyze the given text for named entities and part-of-speech information.\n",
        "3.Provide the output in JSON format, with each named entity as a key-value pair, where the key is the type of the entity (e.g., `People Name,` `Place Name,` `Product Name,` `Country,` `Importance Word,` `Specific/Scientific Word`) and the value is a dictionary containing the actual entity, additional details, and part-of-speech information.\n",
        "4.Ensure that the JSON output is well-structured and easy to understand.\n",
        "5.Sample Text for NER:\n",
        "\n",
        "`The famous scientist Marie Curie was born on November 7, 1867, in Warsaw, Poland. She made groundbreaking contributions to the field of physics and chemistry. Curie was the first woman to win a Nobel Prize and remains an inspiration for scientists worldwide.`\n",
        "\n",
        "Expected Output (JSON):\n",
        "{{\n",
        "  `People Name`: {{\n",
        "    `word`: [`Marie Curie`],\n",
        "    `POS`: [`NNP`]\n",
        "  }},\n",
        "  `Importance Word`: {{\n",
        "    `word`: [`groundbreaking`],\n",
        "    `POS`: [`JJ`]\n",
        "  }},\n",
        "  `Specific/Scientific Word`: {{\n",
        "    `word`: [`physics`, `chemistry`],\n",
        "    `POS`: [`NNS`, `NN`]\n",
        "  }},\n",
        "  `Place Name`: {{\n",
        "    `word`: [`Warsaw`, `Poland`],\n",
        "    `POS`: [`NNP`, `NNP`]\n",
        "  }},\n",
        "  `Country`: {{\n",
        "    `word`: [`Poland`],\n",
        "    `POS`: [`NNP`]\n",
        "  }},\n",
        "  `Product Name`: {{\n",
        "    `word`: [`Nobel Prize`],\n",
        "    `POS`: [`NNP`]\n",
        "  }}\n",
        "}}\n",
        "\n",
        "Text input\n",
        "{cnn_news['body']}\n",
        "\"\"\"\n"
      ],
      "metadata": {
        "id": "C7C4MF8wPyfi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "answer = llm.predict(prompt)\n",
        "print(answer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tLmpfQ_eQ0-5",
        "outputId": "d77fec61-5b7d-46aa-ee64-fc8983653dbd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"Product Name\": {\n",
            "    \"word\": [\"New Shepard\"],\n",
            "    \"POS\": [\"NNP\"]\n",
            "  },\n",
            "  \"Place Name\": {\n",
            "    \"word\": [\"West Texas\"],\n",
            "    \"POS\": [\"NNP\"]\n",
            "  },\n",
            "  \"Specific/Scientific Word\": {\n",
            "    \"word\": [\"microgravity\", \"Max Q\", \"atmosphere\", \"engine\", \"nozzle\", \"exhaust\", \"computers\"],\n",
            "    \"POS\": [\"NN\", \"NNP\", \"NN\", \"NN\", \"NN\", \"NN\", \"NNS\"]\n",
            "  },\n",
            "  \"People Name\": {\n",
            "    \"word\": [\"Erika Wagner\", \"Jeff Bezos\"],\n",
            "    \"POS\": [\"NNP\", \"NNP\"]\n",
            "  },\n",
            "  \"Importance Word\": {\n",
            "    \"word\": [\"successful\", \"failed\", \"uncrewed\", \"massive\", \"safely\", \"intended\", \"consecutive\"],\n",
            "    \"POS\": [\"JJ\", \"VBD\", \"JJ\", \"JJ\", \"RB\", \"VBN\", \"JJ\"]\n",
            "  },\n",
            "  \"Country\": {\n",
            "    \"word\": [\"Texas\"],\n",
            "    \"POS\": [\"NNP\"]\n",
            "  }\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "eval(answer)['Product Name']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W7ogamnARBms",
        "outputId": "2874f48c-6a03-474d-8fcd-5288ea850925"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'word': ['New Shepard'], 'POS': ['NNP']}"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# POS + Consequence"
      ],
      "metadata": {
        "id": "afth1UKzSs3W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = f\"\"\"Hello! I need your help with a task related to understanding and extracting important information from text. Specifically, I'm interested in identifying and classifying named entities (people's names, place names, product names, countries, important words, specific/scientific words, and words related to future trends or consequences) in a given text. Additionally, I'd like to know the part-of-speech for each word.\n",
        "\n",
        "Task:\n",
        "\n",
        "Please use ChatGPT to perform a Named Entity Recognition (NER) task on the provided text. Extract and categorize the named entities, provide information on their types, and include the part-of-speech for each word in JSON format. For example, if the text mentions a person's name, place name, product name, country, important word, specific/scientific word, or a word related to future trends or consequences, please identify and label them accordingly in the JSON output. Additionally, include the part-of-speech for each word.\n",
        "\n",
        "Instructions:\n",
        "\n",
        "Begin by introducing yourself and acknowledging the task.\n",
        "Analyze the given text for named entities and part-of-speech information.\n",
        "Provide the output in JSON format, with each named entity as a key-value pair, where the key is the type of the entity (e.g., `People Name,` `Place Name,` `Product Name,` `Country,` `Importance Word,` `Specific/Scientific Word,` `Future Trend/Consequence Word`) and the value is a dictionary containing the actual entity, additional details, and part-of-speech information.\n",
        "Ensure that the JSON output is well-structured and easy to understand.\n",
        "Sample Text for NER:\n",
        "\n",
        "`The famous scientist Marie Curie was born on November 7, 1867, in Warsaw, Poland. She made groundbreaking contributions to the field of physics and chemistry. Curie was the first woman to win a Nobel Prize and remains an inspiration for scientists worldwide. Her discoveries have had a profound consequence on the world of science.`\n",
        "\n",
        "\n",
        "Expected Output (JSON):\n",
        "{{\n",
        "  `People Name`: {{\n",
        "    `word`: [`Marie Curie`],\n",
        "    `POS`: [`NNP`]\n",
        "  }},\n",
        "  `Importance Word`: {{\n",
        "    `word`: [`groundbreaking`],\n",
        "    `POS`: [`JJ`]\n",
        "  }},\n",
        "  `Specific/Scientific Word`: {{\n",
        "    `word`: [`physics`, `chemistry`],\n",
        "    `POS`: [`NNS`, `NN`]\n",
        "  }},\n",
        "  `Place Name`: {{\n",
        "    `word`: [`Warsaw`, `Poland`],\n",
        "    `POS`: [`NNP`, `NNP`]\n",
        "  }},\n",
        "  `Country`: {{\n",
        "    `word`: [`Poland`],\n",
        "    `POS`: [`NNP`]\n",
        "  }},\n",
        "  `Product Name`: {{\n",
        "    `word`: [`Nobel Prize`],\n",
        "    `POS`: [`NNP`]\n",
        "  }},\n",
        "  `Future Trend/Consequence Word`: {{\n",
        "    `word`: [`consequence`, `profound`],\n",
        "    `POS`: [`NN`, `JJ`]\n",
        "  }}\n",
        "}}\n",
        "\n",
        "\n",
        "Text input\n",
        "{cnn_news['body']}\n",
        "\"\"\"\n"
      ],
      "metadata": {
        "id": "6jlOHp1SSrzq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "answer = llm.predict(prompt)\n",
        "print(answer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LLObjdtZUFKI",
        "outputId": "10434ded-1969-4a90-dfe8-daed77d19b24"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"Product Name\": {\n",
            "    \"word\": [\"New Shepard\"],\n",
            "    \"POS\": [\"NNP\"]\n",
            "  },\n",
            "  \"Place Name\": {\n",
            "    \"word\": [\"Blue Origin\", \"West Texas\"],\n",
            "    \"POS\": [\"NNP\", \"NNP\"]\n",
            "  },\n",
            "  \"People Name\": {\n",
            "    \"word\": [\"Erika Wagner\", \"Jeff Bezos\"],\n",
            "    \"POS\": [\"NNP\", \"NNP\"]\n",
            "  },\n",
            "  \"Future Trend/Consequence Word\": {\n",
            "    \"word\": [\"anticipated\", \"restart\", \"recuperating\", \"failure\", \"successful\", \"safely\", \"intended\", \"consecutive\", \"successful\"],\n",
            "    \"POS\": [\"VBN\", \"VB\", \"VBG\", \"NN\", \"JJ\", \"RB\", \"VBN\", \"JJ\", \"JJ\"]\n",
            "  },\n",
            "  \"Country\": {\n",
            "    \"word\": [\"United States\"],\n",
            "    \"POS\": [\"NNPS\"]\n",
            "  },\n",
            "  \"Specific/Scientific Word\": {\n",
            "    \"word\": [\"science\", \"experiments\", \"microgravity\", \"aerospace\", \"atmosphere\", \"engine\", \"nozzle\", \"exhaust\", \"computers\"],\n",
            "    \"POS\": [\"NN\", \"NNS\", \"NN\", \"NN\", \"NN\", \"NN\", \"NN\", \"NN\", \"NNS\"]\n",
            "  }\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# COUNT TOKEN\n"
      ],
      "metadata": {
        "id": "spM4jtrtTHSq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tiktoken"
      ],
      "metadata": {
        "id": "9UuMyfU4Sja-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoding = tiktoken.get_encoding(\"cl100k_base\") # for gpt-4, gpt-3.5-turbo, text-embedding-ada-002"
      ],
      "metadata": {
        "id": "vu-3iR51SjdR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_tokens = len(encoding.encode(cnn_news['body']))\n",
        "num_tokens"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cuSBfUIFSjfV",
        "outputId": "d0b590af-9ef1-4b7b-d233-5ee08c9cb916"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "476"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# INPUT $0.0010 / 1K tokens\tOUTPUT $0.0020 / 1K tokens\n",
        "\n",
        "def total_price(texts, rate_baht_per_dollar):\n",
        "    total_token = sum([len(encoding.encode(text)) for text in texts])\n",
        "    dollar_price = total_token * 0.0010 / 1000\n",
        "    baht_price = dollar_price * rate_baht_per_dollar\n",
        "    return dollar_price, baht_price"
      ],
      "metadata": {
        "id": "CiYupkbmTVQm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dollar_price, baht_price = total_price(cnn_news['body'], 35)\n",
        "dollar_price, baht_price"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KqzPEUAkTiQQ",
        "outputId": "a0df2dee-a3e5-450b-bdce-a26b3b7e13df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.002415, 0.084525)"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    }
  ]
}